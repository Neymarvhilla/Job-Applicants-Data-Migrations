{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88c6787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the pandas module\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426f5aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the numpy module\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26ed38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os module\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d876bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The base directory\n",
    "base_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e3e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a root directory (necessary since we would have the code in its own folder)\n",
    "root_directory = os.path.abspath(os.path.join(base_directory, \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5093d65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the path to the templates folder holding the excel templates\n",
    "templates_path = os.path.join(root_directory,\"data\",\"Templates\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b3388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the path to the historic_data_folder holding the legacy csv and legacy resume folder\n",
    "historic_data_path = os.path.join(root_directory,\"data\",\"Historic_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6552884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the path to the resume folder\n",
    "resume_path = os.path.join(historic_data_path,\"Resumes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539bff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the path to the folder holding excel files that we are writing to\n",
    "transformed_file_path = os.path.join(root_directory,\"transformed_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c84990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructs to the full path to the legacy csv\n",
    "legacy_csv_file_path = os.path.join(historic_data_path,\"candidates.presence.latest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdd8733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the historical dataframe from the legacy csv path\n",
    "historical_data_df = pd.read_csv(legacy_csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be1d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize column names to remove leading or trailing spaces\n",
    "historical_data_df.columns = historical_data_df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7629584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to Candidates Template excel file\n",
    "candidates_template_file_path = os.path.join(templates_path,\"Candidates Template.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff2080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to Application Template Excel File\n",
    "applications_template_file_path = os.path.join(templates_path,\"Applications Template.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d34d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to Jobs Template Excel File\n",
    "jobs_template_file_path = os.path.join(templates_path,\"Jobs Template.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f85ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to Attachments Template Excel File\n",
    "attachments_template_file_path = os.path.join(templates_path,\"Attachments Template.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f48ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick look at the column names\n",
    "historical_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a121a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d34003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to be dropped\n",
    "dropped_columns = [\"Company\", \"Schools\", \"Zip\", \"Snoozed Until\", \"Requisition For Hire ID\", \"Requisition For Hire Requisition Code\", \"Profile Archive Reason\", \"Start Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a1c8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops the columns in our dropped_columns list\n",
    "def drop_columns(source_df, column_list):\n",
    "    for column in column_list:\n",
    "        if column in source_df.columns:\n",
    "            source_df = source_df.drop(columns=[column])\n",
    "            \n",
    "    return source_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6eb6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to convert to nullable string\n",
    "nullable_string_columns = [\"Email\", \"Phone\", \"Address\", \"City\", \"State\", \"Links\", \"Files\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7619e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts column datatypes to nullable string datatype\n",
    "def convert_to_nullable_string(source_df, column_list):\n",
    "    for column in column_list:\n",
    "        if column in source_df.columns:\n",
    "            source_df[column] = source_df[column].astype(\"string\")\n",
    "    return source_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f89d38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to convert to datetime64\n",
    "datetime64_columns = [\"Created At\", \"Archived At\", \"Hired\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a164e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts column datatypes to datetime64 datatype\n",
    "def convert_to_datetime64(source_df, column_list):\n",
    "    for column in column_list:\n",
    "        if column in source_df.columns:\n",
    "            source_df[column] = pd.to_datetime(source_df[column], errors='coerce')\n",
    "    return source_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc5930",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_df = drop_columns(historical_data_df, dropped_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995ff45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_df = convert_to_nullable_string(historical_data_df, nullable_string_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7244cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_df = convert_to_datetime64(historical_data_df, datetime64_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e44f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Schema\n",
    "historical_data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e891e140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the full address            \n",
    "def get_address(row):\n",
    "    address_parts = []\n",
    "    if pd.notnull(row[\"Address\"]):\n",
    "        address_parts.append(row[\"Address\"])\n",
    "    if pd.notnull(row[\"City\"]):\n",
    "        address_parts.append(row[\"City\"])\n",
    "    if pd.notnull(row[\"State\"]):\n",
    "        address_parts.append(row[\"State\"])\n",
    "    return \", \".join(address_parts) if address_parts else np.nan\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd36254",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_df[\"Address\"] = historical_data_df.apply(get_address, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6032b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"State\" and \"City\" columns\n",
    "historical_data_df = historical_data_df.drop(columns=[\"State\", \"City\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b88c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip whitespace from all nullable \"string\" columns\n",
    "historical_data_df = historical_data_df.apply(lambda col: col.str.strip() if pd.api.types.is_string_dtype(col) else col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9814696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip whitespace from all string columns\n",
    "historical_data_df = historical_data_df.apply(lambda col: col.str.strip() if col.dtype == \"object\" else col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d15bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Candidates File\n",
    "def transform_candidates(source_df, template_file_path):\n",
    "    \n",
    "    # Create a list of the necessary columns\n",
    "    required_columns = [\"Contact ID\", \"Candidate Name\", \"Email\", \"Phone\", \"Address\", \"Links\"]\n",
    "    candidates_df = source_df[required_columns].copy()\n",
    "    \n",
    "    # split Candidate Name into two separate columns for first name and last name\n",
    "    candidates_df[[\"First name\", \"Last name\"]] = candidates_df[\"Candidate Name\"].str.split(\" \", n=1, expand=True)\n",
    "    \n",
    "    # Clean up the \"Phone\" column to only have digits as values, e.g. 6137892379\n",
    "    candidates_df[\"Phone\"] = candidates_df[\"Phone\"].astype(\"string\").str.replace(r\"\\D\", \"\", regex=True)\n",
    "    \n",
    "    # Rename columns according to the standard provided in the template\n",
    "    candidates_df = candidates_df.rename(columns=\n",
    "                        {\"Contact ID\" : \"Candidate ID\", \n",
    "                         \"Links\":\"Website\"})\n",
    "    \n",
    "    # Ensure correct ordering of columns\n",
    "    template_cols = pd.read_excel(template_file_path,index_col=0).columns.tolist()\n",
    "    final_candidates_df = candidates_df[template_cols]\n",
    "    \n",
    "    return final_candidates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eefed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get the values in the \"Status\" column we will be creating.\n",
    "# If the \"Hired\" column is not null, it means the applicant was hired.\n",
    "\n",
    "def derive_status(row):\n",
    "    \n",
    "    if pd.notnull(row[\"Hired\"]):\n",
    "        return \"Hired\"\n",
    "    else:\n",
    "        return \"Rejected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc7a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Applications File\n",
    "def transform_applications(source_df, template_file_path):\n",
    "    \n",
    "    \n",
    "    # Create a list of required columns\n",
    "    required_columns = [\"App ID\", \"Contact ID\", \"Hired\", \"Archive Reason\", \"Posting Title\", \"Sources\", \"Current Stage\", \"Created At (GMT)\", \"Archived At (GMT)\"]\n",
    "    applications_df = source_df[required_columns].copy()\n",
    "    \n",
    "    # Derive the \"Status\" column from the \"Hired\" column\n",
    "    applications_df[\"Status\"] = applications_df.apply(derive_status, axis=1)\n",
    "    \n",
    "    # Rename columns to match template standards\n",
    "    applications_df = applications_df.rename(columns={\"App ID\":\"Application ID\",\n",
    "                                                      \"Contact ID\":\"Candidate ID\",\n",
    "                                                      \"Archive Reason\":\"Rejection Reason\", \n",
    "                                                      \"Posting Title\":\"Job Name\",\n",
    "                                                      \"Sources\":\"Source\",\n",
    "                                                      \"Current Stage\":\"Stage\",\n",
    "                                                      \"Created At (GMT)\":\"Application Date\",\n",
    "                                                      \"Archived At (GMT)\":\"Rejection Date\",\n",
    "                                                      \"Hired\":\"Hire Date\"})\n",
    "    \n",
    "    # We want null the values in the \"Rejection Reason\" column that are \"Hired\" so we can set them to NaN\n",
    "    applications_df.loc[applications_df[\"Rejection Reason\"] == \"Hired\", \"Rejection Reason\"] = np.nan\n",
    "    \n",
    "    # Ensure correct ordering of columns\n",
    "    template_cols = pd.read_excel(template_file_path,index_col=0).columns.tolist()\n",
    "    final_applications_df = applications_df[template_cols]\n",
    "\n",
    "    return final_applications_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8061ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Jobs File\n",
    "def transform_jobs(source_df, template_file_path):\n",
    "    \n",
    "    # Create the list of required columns\n",
    "    required_columns = [\"Posting Title\", \"Posting Team\", \"Posting Level\"]\n",
    "    jobs_df = source_df[required_columns].copy()\n",
    "    \n",
    "    # Rename colums to match template standards\n",
    "    jobs_df = jobs_df.rename(columns={\"Posting Title\":\"Job Name\",\n",
    "                                      \"Posting Team\":\"Department\",\n",
    "                                      \"Posting Level\":\"Office\"})\n",
    "    \n",
    "    # Add optional columns with NaN values in case future data includes them\n",
    "    jobs_df[\"Open Date\"] = np.nan\n",
    "    jobs_df[\"Closed Date\"] = np.nan\n",
    "    jobs_df[\"Description\"] = np.nan\n",
    "    \n",
    "    # Ensure correct ordering of columns\n",
    "    template_cols = pd.read_excel(template_file_path,index_col=0).columns.tolist()\n",
    "    final_jobs_df = jobs_df[template_cols]\n",
    "    \n",
    "    return final_jobs_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5170e50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list of resume file paths from a folder path containing the candidate's resume files.\n",
    "def get_resume_list(folder_path):\n",
    "    \n",
    "    resume_list = [os.path.join(folder_path, resume) for resume in os.listdir(folder_path) if resume.lower().endswith(\".pdf\") \n",
    "                   and os.path.isfile(os.path.join(folder_path, resume))]\n",
    "    return resume_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb75e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if the values in the \"File\" column are in our list of resumes.\n",
    "# If they are then the file provided is a resume.\n",
    "# If no file was provided we return null.\n",
    "def file_type(row, resume_list):\n",
    "    \n",
    "    # we check all the rows in our dataframe for the condition\n",
    "    if pd.notnull(row[\"Files\"]):\n",
    "        file = str(row[\"Files\"]).lower()\n",
    "        for path in resume_list:\n",
    "            file_name = os.path.basename(path).lower()\n",
    "            if file == file_name:\n",
    "                return \"Resume\"\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193cba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if the values in the \"File\" column are in our list of resumes.\n",
    "# If they are, then we want to return to the full file paths.\n",
    "# If no file was provided, we return null.\n",
    "def file_path(row, resume_list):\n",
    "    if pd.notnull(row[\"Files\"]):\n",
    "        file = str(row[\"Files\"]).lower().strip()\n",
    "        for path in resume_list:\n",
    "            file_name = os.path.basename(path).lower().strip()\n",
    "            if file == file_name:\n",
    "                return path\n",
    "    return np.nan\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e26d882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Attachments File\n",
    "def transform_attachments(source_df, resume_list, template_file_path):\n",
    "    \n",
    "    # Create list of required columns\n",
    "    required_columns = [\"Contact ID\", \"Files\"]\n",
    "    attachments_df = source_df[required_columns].copy()\n",
    "    \n",
    "\n",
    "    # Check if the file is in our list of resume file paths\n",
    "    attachments_df[\"File path\"] = attachments_df.apply(lambda row: file_path(row, resume_list), axis=1)\n",
    "    attachments_df[\"Files\"] = attachments_df.apply(lambda row: file_type(row, resume_list), axis=1)\n",
    "    \n",
    "    # Rename columns to comply with template standards\n",
    "    # I opted to use Contact ID -> Candidate ID since the template allows for choice between Candidate ID and Application ID\n",
    "    attachments_df = attachments_df.rename(columns={\"Contact ID\":\"Application ID or Candidate ID\", \n",
    "                                                    \"Files\":\"Attachment Type\"})\n",
    "    \n",
    "    # Ensure correct ordering of columns\n",
    "    template_cols = pd.read_excel(template_file_path,index_col=0).columns.tolist()\n",
    "    final_attachments_df = attachments_df[template_cols]\n",
    "    \n",
    "    return final_attachments_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daf0c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the resume folder\n",
    "resume_folder = resume_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d48bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list holding resume file paths\n",
    "resume_list = get_resume_list(resume_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d4bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_candidates_df = transform_candidates(historical_data_df, candidates_template_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c60ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_applications_df = transform_applications(historical_data_df, applications_template_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528ec9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_jobs_df = transform_jobs(historical_data_df, jobs_template_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8681107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_attachments_df = transform_attachments(historical_data_df, resume_list, attachments_template_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ebd19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_candidates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1cb177",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_applications_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06e9473",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba84f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_attachments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4918d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to presentation/transformed layer\n",
    "candidates_presentation = os.path.join(transformed_file_path,\"Candidates Template.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03863d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to presentation/transformed layer\n",
    "applications_presentation = os.path.join(transformed_file_path,\"Applications Template.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f028e95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to presentation/transformed layer\n",
    "jobs_presentation = os.path.join(transformed_file_path,\"Jobs Template.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394864fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to presentation/transformed layer\n",
    "attachments_presentation = os.path.join(transformed_file_path,\"Attachments Template.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b725576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to excel files\n",
    "def write_to_excel(transformed_df, file_path):\n",
    "    try:\n",
    "        transformed_df.to_excel(file_path, index=False)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to Excel: {e}\")\n",
    "        return False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c268fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_excel(transformed_candidates_df, candidates_presentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3dda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_excel(transformed_applications_df, applications_presentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1921709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_excel(transformed_jobs_df, jobs_presentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99985841",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_excel(transformed_attachments_df, attachments_presentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f974d5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
